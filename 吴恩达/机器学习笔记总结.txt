第一周
线性回归  h是θx  代价函数是最小二乘
梯度下降：批量梯度下降（矩阵表示：正规方程）

第二周
梯度下降 1 特征缩放 帮助算法更快的收敛
	     2 向量化

第三周
逻辑回归 h是sigmod（θx）代价函数是交叉熵
过拟合 ：1 PCA算法 选择或者丢弃掉错误的特征
         2 正则化  带约束条件的优化问题 
			 L1正则化可以产生稀疏权重矩阵，即大部分w为0，只有少数w非0，可以用于特征选择
			 L2正则化可以防止模型过拟合
		 3 加大数据量

第四周
神经网络概述

第五周
反向传播 
梯度检验
随机初始化

第六周
处理方差和偏差
评估依据 TP TN F1socre

第七周
支持向量机 大间距分类器   参数向量和决策边界90正交，想要p*θ充分大，就要投影充分大，θ我们是希望小的，寻找最大投影。
核函数改造支持向量机，构造非常复杂的非线性分类器、

第八周
聚类 k-means
降维 数据压缩 PCA（具有与数据之间最小投射误差的方向向量构成的矩阵，降到几维取几列）

第九周
异常检测
推荐系统

第十周

